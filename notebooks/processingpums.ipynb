{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUMS Microdata Personas Basic Processing\n",
    "This notebook consumes Public Use Microdata Sample files (PUMS) to create an aggregated and normalized file that includes household and person level data that can be used for analysis and answer specific questions about different types of users of the transportation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUMS IDs for each selected PUMA (Seattle: Downtown, Northeast, Northwest, Southeast, and West)\n",
    "SEATTLE_PUMS = [11601, 11602, 11603, 11604, 11605]\n",
    "\n",
    "# Loading household data for Seattle-only locations\n",
    "df_household = pd.read_csv('ss16hwa.csv')\n",
    "df_household = df_household[df_household['PUMA'].isin(SEATTLE_PUMS)]\n",
    "\n",
    "# Loading person data for Seattle-only locations\n",
    "df_person = pd.read_csv('ss16pwa.csv')\n",
    "df_person = df_person[df_person['PUMA'].isin(SEATTLE_PUMS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Person level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data set for important indices to track \n",
    "df_person = df_person[['PUMA', 'SERIALNO', 'RAC1P', 'AGEP', 'DDRS', 'DEAR', 'DEYE',\n",
    "                        'DOUT', 'DPHY', 'ENG', 'PINCP', 'HISP','PWGTP',\n",
    "                      'JWMNP','JWTR', 'MIG', 'SCHL', 'SEX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = df_person[['PUMA', 'SERIALNO', 'AGEP']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing the PUMA sections & creating dummy variables\n",
    "ps['PUMA'] = ps['PUMA'].replace([11601, 11602, 11603, 11604, 11605], ['NORTHWEST', 'NORTHEAST',\n",
    "                                                                                'DOWNTOWN', 'SOUTHEAST', 'WEST'])\n",
    "# Crating a dummy variable for PUMA \n",
    "dummy_puma = pd.get_dummies(ps['PUMA'])\n",
    "dummy_puma.loc[ps['PUMA'].isnull(), :] = np.nan\n",
    "ps = pd.concat([ps, dummy_puma], axis = 1)\n",
    "\n",
    "# Categorizing RAC1P (preparing for clustering)\n",
    "\"\"\"\n",
    "RAC1P-RACE: \n",
    "    0: White alone\n",
    "    1: Black or African American alone\n",
    "    2: American Indian Alone & Alaska Native alone\n",
    "    3: Asian alone \n",
    "    4: Native Hawaiian & other pacific islander\n",
    "    5: Some other race alone & Two or more races \n",
    "\"\"\"\n",
    "ps['RAC1P'] = df_person['RAC1P'].replace([1, 2, 3, 4, 5, 6, 7, 8, 9], ['WHITE_ALONE', 'BLACK_ALONE', \n",
    "                                                                       'NATIVE_INDIAN', 'NATIVE_INDIAN', \n",
    "                                                                       'NATIVE_INDIAN', 'ASIAN_ALONE', \n",
    "                                                                       'PACIFIC_ISLANDER', 'OTHER_RACE', 'OTHER_RACE'])\n",
    "# Crating a dummy variable for RACE\n",
    "dummy_mode = pd.get_dummies(ps['RAC1P'])\n",
    "dummy_mode.loc[ps['RAC1P'].isnull(), :] = np.nan\n",
    "ps = pd.concat([ps, dummy_mode], axis = 1)\n",
    "\n",
    "#  Categorizing SEX (preparing for clustering)\n",
    "\"\"\"\n",
    "SEX: \n",
    "    0: Male\n",
    "    1: Female\n",
    "\"\"\"\n",
    "ps['SEX'] = df_person['SEX'].replace([1, 2], ['MALE', 'FEMALE'])\n",
    "\n",
    "# Crating a dummy variable for SEX (male vs. female)\n",
    "dummy_mode = pd.get_dummies(ps['SEX'])\n",
    "dummy_mode.loc[ps['SEX'].isnull(), :] = np.nan\n",
    "ps = pd.concat([ps, dummy_mode], axis = 1)\n",
    "\n",
    "# Categorizing travel time to work(preparing for clusterign) --> TRAVEL_TIME_TO_WORK = 'JWMNP'\n",
    "ps['JWMNP'] = pd.to_numeric(df_person['JWMNP'], errors='coerce').fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing the hispanic (hispanic origin of any race) sections (preparing for clustering)\n",
    "\"\"\" \n",
    "HISP: \n",
    "    0: Not hispanic origin\n",
    "    1: Hispanic origin\n",
    "\"\"\"\n",
    "ps['HISP'] = df_person['HISP'].replace([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
    "                                        18, 19, 20, 21, 22, 23, 24], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "                                                        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Categorizing the DDRS (Self-care difficulty) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "DDRS-SELF_CARE_DIFFICULTY: \n",
    "    0: Yes\n",
    "    1: No \n",
    "\"\"\"\n",
    "ps['DDRS'] = df_person['DDRS'].replace([1, 2], [0, 1])\n",
    "\n",
    "# Categorizing the DEAR (hearing difficulty) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "DEAR-HEARING_DIFFICULTY: \n",
    "    0: Yes\n",
    "    1: No\n",
    "\"\"\"\n",
    "ps['DEAR'] = df_person['DEAR'].replace([1, 2], [0, 1])\n",
    "\n",
    "# Categorizing the DEYE (vision difficulty) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "DEYE-VISION_DIFFICULTY:\n",
    "    0: Yes\n",
    "    1: No\n",
    "\"\"\"\n",
    "ps['DEYE'] = df_person['DEYE'].replace([1, 2], [0, 1])\n",
    "\n",
    "# Categorizing the DOUT (independent living difficulty) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "DOUT-INDEPENDENT_LIVING_DIFFICULTY:\n",
    "    0: Yes\n",
    "    1: No\n",
    "    Nan: less than 5 years old\n",
    "\"\"\"\n",
    "ps['DOUT'] = df_person['DOUT'].replace([1, 2], [0, 1])\n",
    "\n",
    "# Categorizing the DDRS (Ambulatory difficulty) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "DPHY-AMBULATORY_DIFFICULTY:\n",
    "    0: Yes\n",
    "    1: No \n",
    "    NaN: less than 5 years old\n",
    "\"\"\"\n",
    "ps['DPHY'] = df_person['DPHY'].replace([1, 2], [0, 1])\n",
    "\n",
    "# Categorizing the ENG (Ability to speak english) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "ENG-ABILITY_TO_SPEAK_ENG\n",
    "    0: Very well \n",
    "    1: Well \n",
    "    2: Not well \n",
    "    3: Not at all \n",
    "    NaN: less than 5 years old\n",
    "\"\"\"\n",
    "ps['ENG'] = df_person['ENG'].replace([1, 2, 3, 4,], [0, 1, 2, 3])\n",
    "\n",
    "# Categorizing the MIG (MOBILITY_STATUS) sections (preparing for clustering)\n",
    "\"\"\"\n",
    "MIG-MOBILITY_STATUS (live here 1 year ago)\n",
    "    0: Yes, same house \n",
    "    1: No, outside US \n",
    "    2: No, different house in US \n",
    "    NaN: less than 1 year old\n",
    "\"\"\"\n",
    "ps['MIG'] = df_person['MIG'].replace([1, 2, 3], [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing mode of transportation to work (preparing for clusterign)\n",
    "\"\"\"\n",
    "JWTR-MODE_TRANSPORTATION \n",
    "   1 - DRIVING\n",
    "   2 - TRANSIT\n",
    "   3 - BIKING\n",
    "   4 - WALKING\n",
    "\"\"\"\n",
    "ps['JWTR'] = df_person['JWTR'].replace([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], ['DRIVING', 'TRANSIT', 'TRANSIT',\n",
    "                                                                                   'TRANSIT', 'TRANSIT', 'TRANSIT',\n",
    "                                                                                   'TRANSIT', 'BIKING', 'BIKING', 'WALKING',\n",
    "                                                                                   np.nan, np.nan])\n",
    "\n",
    "# Crating a dummy variable for JWTR (transportation mode to work)\n",
    "dummy_mode = pd.get_dummies(ps['JWTR'])\n",
    "dummy_mode.loc[ps['JWTR'].isnull(), :] = np.nan\n",
    "ps = pd.concat([ps, dummy_mode], axis = 1)\n",
    "\n",
    "# Categorizing the education section (preparing for clustering)\n",
    "\"\"\" \n",
    "SCHL-Education: calculated from education categories using discretion\n",
    "    0.0 (Less than high school)\n",
    "    0.0 (High school graduate)\n",
    "    1.0 (Some college)\n",
    "    2.0 (Vocational/technical training)\n",
    "    2.0 (Associates degree)\n",
    "    4.0 (Bachelor degree)\n",
    "    6.0 (Graduate/post-graduate degree)\n",
    "    NaN -> missing or N/A\n",
    "\"\"\"\n",
    "ps['SCHL'] = df_person['SCHL'].replace([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
    "                                        18, 19, 20, 21, 22, 23, 24], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                                                                     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, \n",
    "                                                                     1.0, 1.0, 2.0, 4.0, 6.0, 6.0, 6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Household level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data set for important indices to track\n",
    "df_household = df_household[['SERIALNO','HINCP','NP','WGTP']]\n",
    "# Filter for income > 1\n",
    "df_household = df_household[(df_household[\"HINCP\"] > 1)]\n",
    "\n",
    "# Escalate income to current year (2018)\n",
    "# ref http://www.seattle.gov/financedepartment/cpi/documents/US_CPI_History_--_Annual.pdf\n",
    "df_household['HINCP']  = df_household['HINCP'] * 245.120 / 234.067\n",
    "                        \n",
    "# Limit very large households to 8 ppl to correspond with AMI tables\n",
    "df_household['NP'] = np.where(df_household['NP'] > 8,8,df_household['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal + Household data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize personal level data to household level, by calculating means of each features\n",
    "ps_household = ps.groupby(['SERIALNO'], as_index=False).agg({'DOWNTOWN':'mean', 'NORTHEAST': 'mean',\n",
    "                                                            'NORTHWEST':'mean', 'SOUTHEAST':'mean', 'WEST':'mean', 'AGEP':'mean',\n",
    "                                                            'DDRS':'mean', 'ENG':'mean', 'DEAR':'mean', 'DEYE':'mean', 'DOUT':'mean',\n",
    "                                                            'MIG':'mean', 'HISP':'mean', 'JWMNP':'mean', 'BIKING':'mean', 'DRIVING':'mean', \n",
    "                                                            'TRANSIT':'mean', 'WALKING':'mean', 'MALE':'mean', 'FEMALE':'mean', 'SCHL':'mean',\n",
    "                                                            'WHITE_ALONE':'mean', 'BLACK_ALONE':'mean', 'NATIVE_INDIAN':'mean', 'ASIAN_ALONE':'mean',\n",
    "                                                            'PACIFIC_ISLANDER':'mean', 'OTHER_RACE':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>HINCP</th>\n",
       "      <th>NP</th>\n",
       "      <th>WGTP</th>\n",
       "      <th>DOWNTOWN</th>\n",
       "      <th>NORTHEAST</th>\n",
       "      <th>NORTHWEST</th>\n",
       "      <th>SOUTHEAST</th>\n",
       "      <th>WEST</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>...</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>MALE</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>WHITE_ALONE</th>\n",
       "      <th>BLACK_ALONE</th>\n",
       "      <th>NATIVE_INDIAN</th>\n",
       "      <th>ASIAN_ALONE</th>\n",
       "      <th>PACIFIC_ISLANDER</th>\n",
       "      <th>OTHER_RACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>17593.321570</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "      <td>246097.057680</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984</td>\n",
       "      <td>55502.740668</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2319</td>\n",
       "      <td>39794.417838</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2975</td>\n",
       "      <td>78436.892001</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO          HINCP  NP  WGTP  DOWNTOWN  NORTHEAST  NORTHWEST  \\\n",
       "0       127   17593.321570   2   122       0.0        0.0        0.0   \n",
       "1       747  246097.057680   4    74       0.0        0.0        0.0   \n",
       "2      1984   55502.740668   3    69       0.0        1.0        0.0   \n",
       "3      2319   39794.417838   3    89       0.0        0.0        0.0   \n",
       "4      2975   78436.892001   3    77       0.0        1.0        0.0   \n",
       "\n",
       "   SOUTHEAST  WEST       AGEP     ...      WALKING      MALE    FEMALE  \\\n",
       "0        1.0   0.0  56.000000     ...          NaN  0.000000  1.000000   \n",
       "1        1.0   0.0  21.750000     ...          0.0  0.750000  0.250000   \n",
       "2        0.0   0.0  21.666667     ...          0.0  0.666667  0.333333   \n",
       "3        0.0   1.0  38.000000     ...          0.0  0.666667  0.333333   \n",
       "4        0.0   0.0  38.000000     ...          0.0  0.000000  1.000000   \n",
       "\n",
       "       SCHL  WHITE_ALONE  BLACK_ALONE  NATIVE_INDIAN  ASIAN_ALONE  \\\n",
       "0  1.500000          0.0          0.0            0.0          1.0   \n",
       "1  2.500000          0.0          0.0            0.0          1.0   \n",
       "2  2.000000          1.0          0.0            0.0          0.0   \n",
       "3  0.666667          0.0          0.0            0.0          1.0   \n",
       "4  2.333333          1.0          0.0            0.0          0.0   \n",
       "\n",
       "   PACIFIC_ISLANDER  OTHER_RACE  \n",
       "0               0.0         0.0  \n",
       "1               0.0         0.0  \n",
       "2               0.0         0.0  \n",
       "3               0.0         0.0  \n",
       "4               0.0         0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge person level data with household level\n",
    "df_hh_ps = pd.merge(left=df_household, right=ps_household, how='inner', \n",
    "                      left_on='SERIALNO', right_on = 'SERIALNO')\n",
    "df_hh_ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaNs with the average of each column/attributes for each columns that have Nans \n",
    "df_hh_ps['BIKING'] = df_hh_ps['BIKING'].fillna(df_hh_ps[\"BIKING\"].mean())\n",
    "df_hh_ps['TRANSIT'] = df_hh_ps['TRANSIT'].fillna(df_hh_ps[\"TRANSIT\"].mean())\n",
    "df_hh_ps['DRIVING'] = df_hh_ps['DRIVING'].fillna(df_hh_ps[\"DRIVING\"].mean())\n",
    "df_hh_ps['WALKING'] = df_hh_ps['WALKING'].fillna(df_hh_ps[\"TRANSIT\"].mean())\n",
    "df_hh_ps['ENG'] = df_hh_ps['ENG'].fillna(df_hh_ps[\"ENG\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SERIALNO            False\n",
       "HINCP               False\n",
       "NP                  False\n",
       "WGTP                False\n",
       "DOWNTOWN            False\n",
       "NORTHEAST           False\n",
       "NORTHWEST           False\n",
       "SOUTHEAST           False\n",
       "WEST                False\n",
       "AGEP                False\n",
       "DDRS                False\n",
       "ENG                 False\n",
       "DEAR                False\n",
       "DEYE                False\n",
       "DOUT                False\n",
       "MIG                 False\n",
       "HISP                False\n",
       "JWMNP               False\n",
       "BIKING              False\n",
       "DRIVING             False\n",
       "TRANSIT             False\n",
       "WALKING             False\n",
       "MALE                False\n",
       "FEMALE              False\n",
       "SCHL                False\n",
       "WHITE_ALONE         False\n",
       "BLACK_ALONE         False\n",
       "NATIVE_INDIAN       False\n",
       "ASIAN_ALONE         False\n",
       "PACIFIC_ISLANDER    False\n",
       "OTHER_RACE          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there is any NaN (this will be helpful before clustering)\n",
    "df_hh_ps.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hh_ps.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh_ps.to_csv('pums_processed.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
